---
title: Build completely private APIs in Snowflake
codetour: true
category: Learning
date: '2024-09-26'
description: TBD
image: /blog/snowflake-private-api/cover.png
author: Glenn Gillen
authorAvatar: /blog/glenn-gillen.jpg
---

{/* <!-- vale Microsoft.We = NO --> */}
{/* <!-- vale Microsoft.FirstPerson = NO --> */}
{/* <!-- vale ockam.h1-h6_sentence-case = NO --> */}
{/* <!-- vale Microsoft.Contractions = NO --> */}

If you've stored data in Snowflake then chances are you've also got an 
enterprise application that needs to access it, and a common way to do that is 
through an HTTP API. This is your organization's _private_ data though, so 
making it available through an API that is accessible on the _public_ internet 
is not the best approach.

In this guide I'm going to walk you through how to build, deploy, and host a 
_private_ custom API powered by Snowflake.

The API will not have an endpoint exposed to the Internet. Your application 
will, instead, access this API over private endpoints that are only available 
within your enterprise's VPC and other private environments.

The example will build a reporting endpoint (in Python) to return data from the 
[TPC-H](https://docs.snowflake.com/en/user-guide/sample-data-tpch) dataset 
already included in your Snowflake account. 

## Prerequisites

- [Snowflake](https://snowflake.com) Account in an AWS commercial region. 
    - Privileges necessary to create a user, database, warehouse, compute pool, 
repository, network rule, external access integration, and service in Snowflake.
    - Privileges necessary to access the tables in the 
`SNOWFLAKE_SAMPLE_DATA.TPCH_SF10` database and schema.
    - Access to run SQL in the Snowflake console or SnowSQL
- [GitHub](https://github.com/) Account with credits for Codespaces + basic 
experience using git.
- [Ockam](https://www.ockam.io/) Account to securely expose your private API
- Intermediate knowledge of Python

https://github.com/mrinalwadhwa/sfquickstarts/blob/mrinal/add-private-api-guide/site/sfguides/src/build_a_private_custom_api_in_python/build_a_private_custom_api_in_python.md

<CodeTour>

## !!steps Create a Warehouse

Using the Snowflake console or using SnowSQL run these commands

```sql ! tour
USE ROLE ACCOUNTADMIN;
CREATE WAREHOUSE DATA_API_WH WITH WAREHOUSE_SIZE='xsmall';
```

## !!steps 

Creating a warehouse requires `ACCOUNTADMIN` level permissions, so we'll first
switch to this role.

```sql ! tour
--!focus(1:1)
USE ROLE ACCOUNTADMIN;
CREATE WAREHOUSE DATA_API_WH WITH WAREHOUSE_SIZE='xsmall';
```

# !!steps 

We then create a new warehouse named `DATA_API_WH`, with a size of `xsmall`. 

```sql ! tour
USE ROLE ACCOUNTADMIN;
--!focus(1:1)
CREATE WAREHOUSE DATA_API_WH WITH WAREHOUSE_SIZE='xsmall';
```

## !!steps Create app role

```sql ! tour
USE ROLE ACCOUNTADMIN;
CREATE ROLE DATA_API_ROLE;

GRANT USAGE ON WAREHOUSE DATA_API_WH TO ROLE DATA_API_ROLE;
GRANT IMPORTED PRIVILEGES ON DATABASE SNOWFLAKE_SAMPLE_DATA TO ROLE DATA_API_ROLE;

GRANT ROLE DATA_API_ROLE TO ROLE ACCOUNTADMIN;
```
</CodeTour>

## Setup development environment

?? notes on how to setup Codespace

## Python app code

<CodeTour>

## !!steps Top 10 API endpoint

```sql ! tour
@connector.route('/customers/top10')
def customers_top10():
    # Validate arguments
    sdt_str = request.args.get('start_range') or '1995-01-01'
    edt_str = request.args.get('end_range') or '1995-03-31'
    try:
        sdt = datetime.datetime.strptime(sdt_str, dateformat)
        edt = datetime.datetime.strptime(edt_str, dateformat)
    except:
        abort(400, "Invalid start and/or end dates.")
    sql_string = '''
        SELECT
            o_custkey
          , SUM(o_totalprice) AS sum_totalprice
        FROM snowflake_sample_data.tpch_sf10.orders
        WHERE o_orderdate >= '{sdt}'
          AND o_orderdate <= '{edt}'
        GROUP BY o_custkey
        ORDER BY sum_totalprice DESC
        LIMIT 10
    '''
    sql = sql_string.format(sdt=sdt, edt=edt)
    try:
        res = conn.cursor(DictCursor).execute(sql)
        return make_response(jsonify(res.fetchall()))
    except:
        abort(500, "Error reading from Snowflake. Check the logs for details.")
```
</CodeTour>

## Build & publish app container
<CodeTour>

## !!steps 

```bash ! tour
docker build -t dataapi .
```

## !!steps Create the image registry

```sql ! tour
USE ROLE ACCOUNTADMIN;
CREATE DATABASE API;

GRANT ALL ON DATABASE API TO ROLE DATA_API_ROLE;
CREATE SCHEMA IF NOT EXISTS API.PRIVATE;
GRANT ALL ON SCHEMA API.PRIVATE TO ROLE DATA_API_ROLE;

USE DATABASE API;
USE SCHEMA PRIVATE;
CREATE OR REPLACE IMAGE REPOSITORY API;
GRANT READ ON IMAGE REPOSITORY API TO ROLE DATA_API_ROLE;
SHOW IMAGE REPOSITORIES;
```

## !!steps Push the container

```bash ! tour
docker login <repository_url>
docker build -t <repository_url>/dataapi .
docker push <repository_url>/dataapi
```

## !!steps Create the compute pool

```sql ! tour
USE ROLE ACCOUNTADMIN;

CREATE COMPUTE POOL API_POOl
  MIN_NODES = 1
  MAX_NODES = 5
  INSTANCE_FAMILY = CPU_X64_XS;

GRANT USAGE ON COMPUTE POOL API_POOl TO ROLE DATA_API_ROLE;
GRANT MONITOR ON COMPUTE POOL API_POOl TO ROLE DATA_API_ROLE;
```

## !!steps Create the app pool

```sql ! tour
USE ROLE DATA_API_ROLE;

CREATE SERVICE API.PRIVATE.API
 IN COMPUTE POOL API_POOl
 FROM SPECIFICATION
$$
spec:
  container:
  - name: api
    image: /api/private/api/dataapi:latest
    resources:
      requests:
        cpu: 0.5
        memory: 128M
      limits:
        cpu: 1
        memory: 256M
  endpoint:
  - name: api
    port: 8001
    public: false
$$
QUERY_WAREHOUSE = DATA_API_WH;
```

## !!steps 

```sql ! tour
CALL SYSTEM$GET_SERVICE_STATUS('api');
CALL SYSTEM$GET_SERVICE_LOGS('api.private.api', 0, 'api');
```

## !!steps 

```sql ! tour
SHOW ENDPOINTS IN SERVICE API;
```

## !!steps 

```sql ! tour
SHOW SERVICES;
```

</CodeTour>

## Setup Ockam

<CodeTour>

## !!steps 

```bash ! tour
# !focus(1:3)
curl --proto '=https' --tlsv1.2 -sSfL \
  https://install.command.ockam.io | \
  bash && source "$HOME/.ockam/env"
ockam enroll
ockam project ticket --usage-count 1 --expires-in 1h \
  --attribute snowflake-api-service-outlet \
  --relay snowflake-api-service-relay > ticket
```

## !!steps 

```bash ! tour
curl --proto '=https' --tlsv1.2 -sSfL \
  https://install.command.ockam.io | \
  bash && source "$HOME/.ockam/env"
# !focus(1:1)
ockam enroll
ockam project ticket --usage-count 1 --expires-in 1h \
  --attribute snowflake-api-service-outlet \
  --relay snowflake-api-service-relay > ticket
```

## !!steps 

```bash ! tour
curl --proto '=https' --tlsv1.2 -sSfL \
  https://install.command.ockam.io | \
  bash && source "$HOME/.ockam/env"
ockam enroll
# !focus(1:3)
ockam project ticket --usage-count 1 --expires-in 1h \
  --attribute snowflake-api-service-outlet \
  --relay snowflake-api-service-relay > ticket
```

## !!steps

```bash ! tour
ockam project show --jq '.egress_allow_list[]'
```

## !!steps 

```bash ! tour
docker pull ghcr.io/build-trust/ockam
docker tag ghcr.io/build-trust/ockam <repository_url>/ockam
docker push <repository_url>/ockam
```

## !!steps 

```sql ! tour
# Example
VALUE_LIST = ("4ed9ff5d-4953-4080-83c7-e69a3477a545.projects.orchestrator.ockam.io:443");
```

## !!steps 

```sql ! tour
USE ROLE ACCOUNTADMIN;

-- Update VALUE_LIST with ockam egress details
CREATE OR REPLACE NETWORK RULE OCKAM_OUT TYPE = 'HOST_PORT' MODE = 'EGRESS'
VALUE_LIST = ("<EGRESS_ALLOW_LIST>");

CREATE OR REPLACE EXTERNAL ACCESS INTEGRATION OCKAM
ALLOWED_NETWORK_RULES = (OCKAM_OUT) ENABLED = true;

GRANT USAGE ON INTEGRATION OCKAM TO ROLE DATA_API_ROLE;

USE ROLE DATA_API_ROLE;

CREATE SERVICE API_OCKAM_OUTLET
IN COMPUTE POOL API_POOL
FROM SPECIFICATION
$$
spec:
  containers:
  - name: ockam-outlet
    image: /api/private/api/ockam:latest
    args:
      - node
      - create
      - --foreground
      - --enrollment-ticket
      - "<OCKAM_ENROLLMENT_TICKET>"
      - --node-config
      - |
        relay: snowflake-api-service-relay
        tcp-outlet:
          to: api.private.api.snowflakecomputing.internal:8001
          allow: snowflake-api-service-inlet
    env:
        OCKAM_DISABLE_UPGRADE_CHECK: true
        OCKAM_OPENTELEMETRY_EXPORT: false
$$
EXTERNAL_ACCESS_INTEGRATIONS = (OCKAM);
```

## !!steps 

```sql ! tour
CALL SYSTEM$GET_SERVICE_STATUS('API_OCKAM_OUTLET');
CALL SYSTEM$GET_SERVICE_LOGS('API_OCKAM_OUTLET', '0', 'ockam-outlet', 1000);
```

## !!steps 

```bash ! tour
docker run --rm -d  --name ockam-inlet -p 8001:8001 \
  ghcr.io/build-trust/ockam node create --foreground \
  --enrollment-ticket "$(ockam project ticket --usage-count 1 --expires-in 1h --attribute snowflake-api-service-inlet)" \
  --configuration "
    tcp-inlet:
      from: 0.0.0.0:8001
      via: snowflake-api-service-relay
      allow: snowflake-api-service-outlet
  "
```

## !!steps 

```bash ! tour
curl -X GET "http://localhost:8001/connector/customers/top10?start_range=1995-02-01&end_range=1995-02-14"
```

## !!steps 

```bash ! tour
curl -X GET "http://localhost:8001/snowpark/customers/top10?start_range=1995-02-01&end_range=1995-02-14"
```

## !!steps 

```bash ! tour
curl -X GET "http://localhost:8001/connector/clerk/000000002/yearly_sales/1995"
```

## !!steps 

```bash ! tour
curl -X GET "http://localhost:8001/connector/clerk/000000002/yearly_sales/1995"
```

## !!steps 

```sql ! tour
USE ROLE DATA_API_ROLE;
ALTER SERVICE API.PRIVATE.API SUSPEND;
```

## !!steps 

```sql ! tour
USE ROLE DATA_API_ROLE;

DROP SERVICE API.PRIVATE.API;
DROP SERVICE API_OCKAM_OUTLET;
```

## !!steps 

```sql ! tour
USE ROLE ACCOUNTADMIN;

DROP ROLE IF EXISTS DATA_API_ROLE;
DROP DATABASE IF EXISTS API;
DROP INTEGRATION IF EXISTS OCKAM;
DROP COMPUTE POOL IF EXISTS API_POOL;
DROP WAREHOUSE IF EXISTS DATA_API_WH;
```

</CodeTour>